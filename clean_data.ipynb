{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>LocationAbbr</th>\n",
       "      <th>LocationDesc</th>\n",
       "      <th>TopicType</th>\n",
       "      <th>TopicDesc</th>\n",
       "      <th>MeasureDesc</th>\n",
       "      <th>DataSource</th>\n",
       "      <th>Response</th>\n",
       "      <th>Data_Value_Unit</th>\n",
       "      <th>Data_Value_Type</th>\n",
       "      <th>...</th>\n",
       "      <th>GeoLocation</th>\n",
       "      <th>TopicTypeId</th>\n",
       "      <th>TopicId</th>\n",
       "      <th>MeasureId</th>\n",
       "      <th>StratificationID1</th>\n",
       "      <th>StratificationID2</th>\n",
       "      <th>StratificationID3</th>\n",
       "      <th>StratificationID4</th>\n",
       "      <th>SubMeasureID</th>\n",
       "      <th>DisplayOrder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004</td>\n",
       "      <td>OH</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>Tobacco Use – Survey Data</td>\n",
       "      <td>Cigarette Use (Youth)</td>\n",
       "      <td>Smoking Status</td>\n",
       "      <td>YTS</td>\n",
       "      <td>Ever</td>\n",
       "      <td>%</td>\n",
       "      <td>Percentage</td>\n",
       "      <td>...</td>\n",
       "      <td>(40.060210141, -82.404260056)</td>\n",
       "      <td>BEH</td>\n",
       "      <td>106BEH</td>\n",
       "      <td>166SSA</td>\n",
       "      <td>1GEN</td>\n",
       "      <td>8AGE</td>\n",
       "      <td>6RAC</td>\n",
       "      <td>1EDU</td>\n",
       "      <td>YTS08</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>AL</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Tobacco Use – Survey Data</td>\n",
       "      <td>Cigarette Use (Youth)</td>\n",
       "      <td>Smoking Status</td>\n",
       "      <td>YTS</td>\n",
       "      <td>Ever</td>\n",
       "      <td>%</td>\n",
       "      <td>Percentage</td>\n",
       "      <td>...</td>\n",
       "      <td>(32.840571122, -86.631860762)</td>\n",
       "      <td>BEH</td>\n",
       "      <td>106BEH</td>\n",
       "      <td>166SSA</td>\n",
       "      <td>3GEN</td>\n",
       "      <td>8AGE</td>\n",
       "      <td>6RAC</td>\n",
       "      <td>2EDU</td>\n",
       "      <td>YTS08</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>WV</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>Tobacco Use – Survey Data</td>\n",
       "      <td>Smokeless Tobacco Use (Youth)</td>\n",
       "      <td>User Status</td>\n",
       "      <td>YTS</td>\n",
       "      <td>Frequent</td>\n",
       "      <td>%</td>\n",
       "      <td>Percentage</td>\n",
       "      <td>...</td>\n",
       "      <td>(38.665510202, -80.712640135)</td>\n",
       "      <td>BEH</td>\n",
       "      <td>151BEH</td>\n",
       "      <td>169USS</td>\n",
       "      <td>2GEN</td>\n",
       "      <td>8AGE</td>\n",
       "      <td>6RAC</td>\n",
       "      <td>2EDU</td>\n",
       "      <td>YTS12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005</td>\n",
       "      <td>IL</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Tobacco Use – Survey Data</td>\n",
       "      <td>Cigarette Use (Youth)</td>\n",
       "      <td>Smoking Status</td>\n",
       "      <td>YTS</td>\n",
       "      <td>Ever</td>\n",
       "      <td>%</td>\n",
       "      <td>Percentage</td>\n",
       "      <td>...</td>\n",
       "      <td>(40.485010283, -88.997710178)</td>\n",
       "      <td>BEH</td>\n",
       "      <td>106BEH</td>\n",
       "      <td>166SSA</td>\n",
       "      <td>1GEN</td>\n",
       "      <td>8AGE</td>\n",
       "      <td>6RAC</td>\n",
       "      <td>1EDU</td>\n",
       "      <td>YTS08</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005</td>\n",
       "      <td>CT</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Tobacco Use – Survey Data</td>\n",
       "      <td>Smokeless Tobacco Use (Youth)</td>\n",
       "      <td>User Status</td>\n",
       "      <td>YTS</td>\n",
       "      <td>Ever</td>\n",
       "      <td>%</td>\n",
       "      <td>Percentage</td>\n",
       "      <td>...</td>\n",
       "      <td>(41.56266102, -72.649840952)</td>\n",
       "      <td>BEH</td>\n",
       "      <td>151BEH</td>\n",
       "      <td>169USS</td>\n",
       "      <td>2GEN</td>\n",
       "      <td>8AGE</td>\n",
       "      <td>6RAC</td>\n",
       "      <td>2EDU</td>\n",
       "      <td>YTS11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR LocationAbbr   LocationDesc                  TopicType  \\\n",
       "0  2004           OH           Ohio  Tobacco Use – Survey Data   \n",
       "1  2008           AL        Alabama  Tobacco Use – Survey Data   \n",
       "2  2015           WV  West Virginia  Tobacco Use – Survey Data   \n",
       "3  2005           IL       Illinois  Tobacco Use – Survey Data   \n",
       "4  2005           CT    Connecticut  Tobacco Use – Survey Data   \n",
       "\n",
       "                       TopicDesc     MeasureDesc DataSource  Response  \\\n",
       "0          Cigarette Use (Youth)  Smoking Status        YTS      Ever   \n",
       "1          Cigarette Use (Youth)  Smoking Status        YTS      Ever   \n",
       "2  Smokeless Tobacco Use (Youth)     User Status        YTS  Frequent   \n",
       "3          Cigarette Use (Youth)  Smoking Status        YTS      Ever   \n",
       "4  Smokeless Tobacco Use (Youth)     User Status        YTS      Ever   \n",
       "\n",
       "  Data_Value_Unit Data_Value_Type  ...                    GeoLocation  \\\n",
       "0               %      Percentage  ...  (40.060210141, -82.404260056)   \n",
       "1               %      Percentage  ...  (32.840571122, -86.631860762)   \n",
       "2               %      Percentage  ...  (38.665510202, -80.712640135)   \n",
       "3               %      Percentage  ...  (40.485010283, -88.997710178)   \n",
       "4               %      Percentage  ...   (41.56266102, -72.649840952)   \n",
       "\n",
       "  TopicTypeId TopicId  MeasureId  StratificationID1  StratificationID2  \\\n",
       "0         BEH  106BEH     166SSA               1GEN               8AGE   \n",
       "1         BEH  106BEH     166SSA               3GEN               8AGE   \n",
       "2         BEH  151BEH     169USS               2GEN               8AGE   \n",
       "3         BEH  106BEH     166SSA               1GEN               8AGE   \n",
       "4         BEH  151BEH     169USS               2GEN               8AGE   \n",
       "\n",
       "   StratificationID3 StratificationID4 SubMeasureID DisplayOrder  \n",
       "0               6RAC              1EDU        YTS08            8  \n",
       "1               6RAC              2EDU        YTS08            8  \n",
       "2               6RAC              2EDU        YTS12           12  \n",
       "3               6RAC              1EDU        YTS08            8  \n",
       "4               6RAC              2EDU        YTS11           11  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10600 entries, 0 to 10599\n",
      "Data columns (total 31 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   YEAR                        10600 non-null  int64  \n",
      " 1   LocationAbbr                10600 non-null  object \n",
      " 2   LocationDesc                10600 non-null  object \n",
      " 3   TopicType                   10600 non-null  object \n",
      " 4   TopicDesc                   10600 non-null  object \n",
      " 5   MeasureDesc                 10600 non-null  object \n",
      " 6   DataSource                  10600 non-null  object \n",
      " 7   Response                    8190 non-null   object \n",
      " 8   Data_Value_Unit             10600 non-null  object \n",
      " 9   Data_Value_Type             10600 non-null  object \n",
      " 10  Data_Value                  10080 non-null  float64\n",
      " 11  Data_Value_Footnote_Symbol  517 non-null    object \n",
      " 12  Data_Value_Footnote         517 non-null    object \n",
      " 13  Data_Value_Std_Err          10080 non-null  float64\n",
      " 14  Low_Confidence_Limit        10083 non-null  float64\n",
      " 15  High_Confidence_Limit       10080 non-null  float64\n",
      " 16  Sample_Size                 10080 non-null  float64\n",
      " 17  Gender                      10600 non-null  object \n",
      " 18  Race                        10600 non-null  object \n",
      " 19  Age                         10600 non-null  object \n",
      " 20  Education                   10600 non-null  object \n",
      " 21  GeoLocation                 10596 non-null  object \n",
      " 22  TopicTypeId                 10600 non-null  object \n",
      " 23  TopicId                     10600 non-null  object \n",
      " 24  MeasureId                   10600 non-null  object \n",
      " 25  StratificationID1           10600 non-null  object \n",
      " 26  StratificationID2           10600 non-null  object \n",
      " 27  StratificationID3           10600 non-null  object \n",
      " 28  StratificationID4           10600 non-null  object \n",
      " 29  SubMeasureID                10600 non-null  object \n",
      " 30  DisplayOrder                10600 non-null  int64  \n",
      "dtypes: float64(5), int64(2), object(24)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B\n",
      "0  1  4\n",
      "1  2  5\n",
      "2  3  6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {'A': [1, 2, 3],\n",
    "        'B': [4, 5, 6],\n",
    "        'C': [7, 8, 9]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Drop column 'C'\n",
    "df = df.drop(columns=['C'])\n",
    "\n",
    "# Alternatively, you can also use df.drop() without specifying the 'columns' parameter:\n",
    "# df = df.drop('C', axis=1)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'your_dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Step 2: Load your dataset into a pandas DataFrame\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myour_dataset.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Step 3: Separate the features from the target variable (if applicable)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m X \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_column\u001b[39m\u001b[38;5;124m'\u001b[39m])  \u001b[38;5;66;03m# Features\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'your_dataset.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 2: Load your dataset into a pandas DataFrame\n",
    "data = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Step 3: Separate the features from the target variable (if applicable)\n",
    "X = data.drop(columns=['target_column'])  # Features\n",
    "y = data['target_column']  # Target variable (if applicable)\n",
    "\n",
    "# Step 4: Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Step 5: Fit the scaler to the features and transform them\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 6 (Optional): Convert the standardized features back into a pandas DataFrame\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Step 7: Perform further analysis or modeling using the standardized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
